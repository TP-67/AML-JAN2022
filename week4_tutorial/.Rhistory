# Import libraries
library(tidyverse)
library(DataExplorer)
library(VIM)
library(mice)
library(missForest)
# Impute using caret preprocess function
library(caret)
library(psych)
# Load data
df <- read.csv('train.csv', header = T)
df1 <- read.csv('train.csv', header = T)
df2 <- read.csv('train.csv', header = T)
# We use factors for categorical data. Each label has a unique interger as factor.
# When dataframe is loaded, if the 'factor' variables are read  as 'char', you need to convert them to type "factor" with the following:
df$Item_Fat_Content <- as.factor(df$Item_Fat_Content)
df$Item_Type <- as.factor(df$Item_Type)
df$Outlet_Size <- as.factor(df$Outlet_Size)
df$Outlet_Location_Type <- as.factor(df$Outlet_Location_Type)
df$Outlet_Type <- as.factor(df$Outlet_Type)
# Now we convert 'chr' into 'factor'.
str(df)
# Prior to treating missing values any blanks in the dataset must be converted to NA
df <- mutate_all(df, na_if, "")
df1 <- mutate_all(df1, na_if, "")
df2 <- mutate_all(df2, na_if, "")
# View (df)
# If your dataset has no missing values, introduce missing values to illustrate your abilities in imputation.
# df <- prodNA(ds, noNA = 0.1) # introduces 10% missing values at random
# Viewing and counting missing data
# Uses DataExplorer package
plot_missing(df)
# Needs library(VIM)
vim_plot <- aggr(df, numbers=TRUE, prop = c(TRUE, FALSE))
# Uses mice package
md.pattern(df)
# Explain the plots using references on mice and VIM (Ref: https://www.datacamp.com/community/tutorials/visualize-data-vim-package)
# Reference: https://www.codingprof.com/how-to-replace-nas-with-the-mode-most-frequent-value-in-r/
# Imputing missing values in continuous variables using mean or median.
head(df, 10)
df$Item_Weight = ifelse(is.na(df$Item_Weight),
ave(df$Item_Weight, FUN = function(x) mean(x, na.rm = TRUE)),
df$Item_Weight)
head(df, 10)
# df$Salary = ifelse(is.na(df$Salary),
#                         ave(df$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
#                         df$Salary)
# Imputing missing values of the continuous variable using median.
# This function only impute continuous variables.
head(df1, 10)
preProcValues <- preProcess(df1, method = "medianImpute")
df1 <- predict(preProcValues, df1)
head(df1, 10)
# How would you complete imputing categorical values in this dataset?
# Imputing missing values in categorical variables using mode.
# 1) Create a function that returns mode of a variable.
fun_mode <- function(x) {
# List unique variables.
unique_val <- unique(x)
# Count occurrence of each variable.
unique_num <- tabulate(match(x, unique_val))
# Return the most frequent value.
unique_val[which.max(unique_num)]
}
# 2) Replace NAs with the most frequent value.
# Specify the name of the column that have NAs. Then, use if_else() to find the missing values. Finally, replace NAs with a pre-defined function.
# We must convert chr to factor for Outlet_Size here, because factor variables are not imputable.
head(df1, 10)
df1$Outlet_Size = ifelse(is.na(df1$Outlet_Size),
fun_mode(df1$Outlet_Size),
df1$Outlet_Size)
head(df1, 10)
# Create a function for mode
Mode <- function(x) {
ux <- sort(unique(x))
ux[which.max(tabulate(match(x, ux)))]
}
head(df, 10)
df["Outlet_Size"] <- lapply(df["Outlet_Size"], function(x)
replace(x, is.na(x), Mode(x[!is.na(x)])))
head(df, 10)
# Check if there is any NAs
sum(is.na(df))
# Checking frequencies of factor variables
table (df$Outlet_Size)
# identify non numeric columns
i1 <- !sapply(df, is.numeric)
i1
# Imputing missing values using mice for continuous variables
# Ref: https://rforpoliticalscience.com/2020/07/28/impute-missing-values-with-mice-package-in-r/
head(df2, 10)
imputed_df <- mice(df2, m=3)
df2 <- complete(imputed_df)
head(df2, 10)
# # Imputing missing values using missForest
# index <- c(2, 3)
# dr <- missForest(df2[2, 3], verbose = TRUE) # Is dr a dataframe?
# dq<- dr$ximp # What is dq?
# # View dq and comment
# # If there are any floating values where you expect an integer, round it to integer
# # you may use: dataset$col <- round (dataset$col)
# # Once again View the data and comment
# View(dr)
# View(dq)
# where necessary use the following:
# df$col <- as.factor (df$col)
# df$col <- as.numeric (df$col)
# df$col <- as.character (df$col)
head(df1)
df1$Outlet_Size <- factor(df1$Outlet_Size,
levels = c('High', 'Medium', 'SmallFrance'),
labels = c(1, 2, 3))
head(df1)
# This code is for strings
head(df1)
df1 <- df1 %>% mutate(Item_Fat_Content =
case_when(Item_Fat_Content == "LF" ~ "1",
Item_Fat_Content == "low fat" ~ "2",
Item_Fat_Content == "Low Fat" ~ "3",
Item_Fat_Content == "reg" ~ "4",
Item_Fat_Content == "Regular" ~ "5"))
df1$Item_Fat_Content <- as.numeric(df1$Item_Fat_Content)
head(df1)
# Ref: https://cran.r-project.org/web/packages/DataExplorer/vignettes/dataexplorer-intro.html#correlation-analysis
head(df)
df = df %>% mutate(value = 1)  %>% spread(Item_Fat_Content, value,  fill = 0)
df = df %>% mutate(value = 1)  %>% spread(Item_Type, value,  fill = 0)
df = df %>% mutate(value = 1)  %>% spread(Outlet_Size, value,  fill = 0)
df = df %>% mutate(value = 1)  %>% spread(Outlet_Location_Type, value,  fill = 0)
df = df %>% mutate(value = 1)  %>% spread(Outlet_Type, value,  fill = 0)
head(df)
# dataset_dummified <- dummify(df_test, maxcat = 12L)
# View(dataset_dummified)
# # Given below are only sample codes.
# # You need to change the datset reference in the following code to match with dataframes used earlier in this document
#
# dmy <- dummyVars(" ~ .", data = df)
# dataset_onehot <- data.frame(predict(dmy, newdata = df))
# dataset_onehot
# df$Salary <- (df$Salary - min(df$Salary))/(max(df$Salary) - min(df$Salary))
# df$Salary <- round(df$Salary, digits = 3)
summary(df)
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
index <- c(2, 4, 7)
df[index] <- as.data.frame(lapply(df[index], min_max_norm))
summary(df)
describe(df1)
index <- c(2, 4, 7)
df1[index] <- as.data.frame(lapply(df1[index], function(x) if(is.numeric(x)){
(x-mean(x))/sd(x)
} else x))
describe(df1)
# Import libraries
library(tidyverse)
library(DataExplorer)
library(VIM)
library(mice)
library(missForest)
# Impute using caret preprocess function
library(caret)
library(psych)
# Load data
df <- read.csv('train.csv', header = T)
df1 <- read.csv('train.csv', header = T)
df2 <- read.csv('train.csv', header = T)
# We use factors for categorical data. Each label has a unique interger as factor.
# When dataframe is loaded, if the 'factor' variables are read  as 'char', you need to convert them to type "factor" with the following:
df$Item_Fat_Content <- as.factor(df$Item_Fat_Content)
df$Item_Type <- as.factor(df$Item_Type)
df$Outlet_Size <- as.factor(df$Outlet_Size)
df$Outlet_Location_Type <- as.factor(df$Outlet_Location_Type)
df$Outlet_Type <- as.factor(df$Outlet_Type)
# Now we convert 'chr' into 'factor'.
str(df)
# Prior to treating missing values any blanks in the dataset must be converted to NA
df <- mutate_all(df, na_if, "")
df1 <- mutate_all(df1, na_if, "")
df2 <- mutate_all(df2, na_if, "")
# View (df)
# If your dataset has no missing values, introduce missing values to illustrate your abilities in imputation.
# df <- prodNA(ds, noNA = 0.1) # introduces 10% missing values at random
# Viewing and counting missing data
# Uses DataExplorer package
plot_missing(df)
# Needs library(VIM)
vim_plot <- aggr(df, numbers=TRUE, prop = c(TRUE, FALSE))
# Uses mice package
md.pattern(df)
# Explain the plots using references on mice and VIM (Ref: https://www.datacamp.com/community/tutorials/visualize-data-vim-package)
# Reference: https://www.codingprof.com/how-to-replace-nas-with-the-mode-most-frequent-value-in-r/
# Imputing missing values in continuous variables using mean or median.
head(df, 10)
df$Item_Weight = ifelse(is.na(df$Item_Weight),
ave(df$Item_Weight, FUN = function(x) mean(x, na.rm = TRUE)),
df$Item_Weight)
head(df, 10)
# df$Salary = ifelse(is.na(df$Salary),
#                         ave(df$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
#                         df$Salary)
# Imputing missing values of the continuous variable using median.
# This function only impute continuous variables.
head(df1, 10)
preProcValues <- preProcess(df1, method = "medianImpute")
df1 <- predict(preProcValues, df1)
head(df1, 10)
# How would you complete imputing categorical values in this dataset?
# Imputing missing values in categorical variables using mode.
# 1) Create a function that returns mode of a variable.
fun_mode <- function(x) {
# List unique variables.
unique_val <- unique(x)
# Count occurrence of each variable.
unique_num <- tabulate(match(x, unique_val))
# Return the most frequent value.
unique_val[which.max(unique_num)]
}
# 2) Replace NAs with the most frequent value.
# Specify the name of the column that have NAs. Then, use if_else() to find the missing values. Finally, replace NAs with a pre-defined function.
# We must convert chr to factor for Outlet_Size here, because factor variables are not imputable.
head(df1, 10)
df1$Outlet_Size = ifelse(is.na(df1$Outlet_Size),
fun_mode(df1$Outlet_Size),
df1$Outlet_Size)
head(df1, 10)
# Create a function for mode
Mode <- function(x) {
ux <- sort(unique(x))
ux[which.max(tabulate(match(x, ux)))]
}
head(df, 10)
df["Outlet_Size"] <- lapply(df["Outlet_Size"], function(x)
replace(x, is.na(x), Mode(x[!is.na(x)])))
head(df, 10)
# Check if there is any NAs
sum(is.na(df))
# Checking frequencies of factor variables
table (df$Outlet_Size)
# identify non numeric columns
i1 <- !sapply(df, is.numeric)
i1
# Imputing missing values using mice for continuous variables
# Ref: https://rforpoliticalscience.com/2020/07/28/impute-missing-values-with-mice-package-in-r/
head(df2, 10)
imputed_df <- mice(df2, m=3)
df2 <- complete(imputed_df)
head(df2, 10)
# # Imputing missing values using missForest
# index <- c(2, 3)
# dr <- missForest(df2[2, 3], verbose = TRUE) # Is dr a dataframe?
# dq<- dr$ximp # What is dq?
# # View dq and comment
# # If there are any floating values where you expect an integer, round it to integer
# # you may use: dataset$col <- round (dataset$col)
# # Once again View the data and comment
# View(dr)
# View(dq)
# where necessary use the following:
# df$col <- as.factor (df$col)
# df$col <- as.numeric (df$col)
# df$col <- as.character (df$col)
head(df1)
df1$Outlet_Size <- factor(df1$Outlet_Size,
levels = c('High', 'Medium', 'SmallFrance'),
labels = c(1, 2, 3))
head(df1)
# This code is for strings
head(df1)
df1 <- df1 %>% mutate(Item_Fat_Content =
case_when(Item_Fat_Content == "LF" ~ "1",
Item_Fat_Content == "low fat" ~ "2",
Item_Fat_Content == "Low Fat" ~ "3",
Item_Fat_Content == "reg" ~ "4",
Item_Fat_Content == "Regular" ~ "5"))
df1$Item_Fat_Content <- as.numeric(df1$Item_Fat_Content)
head(df1)
# Ref: https://cran.r-project.org/web/packages/DataExplorer/vignettes/dataexplorer-intro.html#correlation-analysis
head(df)
df = df %>% mutate(value = 1)  %>% spread(Item_Fat_Content, value,  fill = 0)
df = df %>% mutate(value = 1)  %>% spread(Item_Type, value,  fill = 0)
df = df %>% mutate(value = 1)  %>% spread(Outlet_Size, value,  fill = 0)
df = df %>% mutate(value = 1)  %>% spread(Outlet_Location_Type, value,  fill = 0)
df = df %>% mutate(value = 1)  %>% spread(Outlet_Type, value,  fill = 0)
head(df)
# dataset_dummified <- dummify(df_test, maxcat = 12L)
# View(dataset_dummified)
# # Given below are only sample codes.
# # You need to change the datset reference in the following code to match with dataframes used earlier in this document
#
# dmy <- dummyVars(" ~ .", data = df)
# dataset_onehot <- data.frame(predict(dmy, newdata = df))
# dataset_onehot
# df$Salary <- (df$Salary - min(df$Salary))/(max(df$Salary) - min(df$Salary))
# df$Salary <- round(df$Salary, digits = 3)
summary(df)
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
index <- c(2, 4, 7)
df[index] <- as.data.frame(lapply(df[index], min_max_norm))
summary(df)
describe(df1)
index <- c(2, 4, 7)
df1[index] <- as.data.frame(lapply(df1[index], function(x) if(is.numeric(x)){
(x-mean(x))/sd(x)
} else x))
describe(df1)
